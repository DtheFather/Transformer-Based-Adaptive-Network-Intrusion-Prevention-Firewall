{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311829d4-a35c-4007-8ff6-49b3c28794bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb4ecd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>496</td>\n",
       "      <td>0</td>\n",
       "      <td>90909.0902</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1762</td>\n",
       "      <td>0</td>\n",
       "      <td>125000.0003</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0051</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>166666.6608</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>udp</td>\n",
       "      <td>-</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2126</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0025</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
       "0   1  0.000011   udp       -   INT      2      0     496       0   \n",
       "1   2  0.000008   udp       -   INT      2      0    1762       0   \n",
       "2   3  0.000005   udp       -   INT      2      0    1068       0   \n",
       "3   4  0.000006   udp       -   INT      2      0     900       0   \n",
       "4   5  0.000010   udp       -   INT      2      0    2126       0   \n",
       "\n",
       "          rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
       "0   90909.0902  ...                 1               2             0   \n",
       "1  125000.0003  ...                 1               2             0   \n",
       "2  200000.0051  ...                 1               3             0   \n",
       "3  166666.6608  ...                 1               3             0   \n",
       "4  100000.0025  ...                 1               3             0   \n",
       "\n",
       "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
       "0           0                 0           1           2                0   \n",
       "1           0                 0           1           2                0   \n",
       "2           0                 0           1           3                0   \n",
       "3           0                 0           2           3                0   \n",
       "4           0                 0           2           3                0   \n",
       "\n",
       "   attack_cat  label  \n",
       "0      Normal      0  \n",
       "1      Normal      0  \n",
       "2      Normal      0  \n",
       "3      Normal      0  \n",
       "4      Normal      0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_path = \"../data/UNSW-NB15/UNSW_NB15_training-set.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9134772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((82332, 20), (82332,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [\n",
    "    \"dur\",\n",
    "    \"spkts\",\n",
    "    \"dpkts\",\n",
    "    \"sbytes\",\n",
    "    \"dbytes\",\n",
    "    \"rate\",\n",
    "    \"sttl\",\n",
    "    \"dttl\",\n",
    "    \"sload\",\n",
    "    \"dload\",\n",
    "    \"sloss\",\n",
    "    \"dloss\",\n",
    "    \"sinpkt\",\n",
    "    \"dinpkt\",\n",
    "    \"smean\",\n",
    "    \"dmean\",\n",
    "    \"ct_srv_src\",\n",
    "    \"ct_state_ttl\",\n",
    "    \"ct_dst_ltm\",\n",
    "    \"ct_src_dport_ltm\"\n",
    "]\n",
    "\n",
    "label_col = \"label\"\n",
    "\n",
    "X = df[feature_cols].astype(\"float32\").values\n",
    "y = df[label_col].astype(\"int64\").values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adb871bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((65865, 20), (16467, 20))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_np, X_val_np, y_train_np, y_val_np = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_np)\n",
    "X_val_scaled = scaler.transform(X_val_np)\n",
    "\n",
    "X_train_scaled.shape, X_val_scaled.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a65b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train_scaled).float()\n",
    "y_train_tensor = torch.from_numpy(y_train_np).float()\n",
    "\n",
    "X_val_tensor = torch.from_numpy(X_val_scaled).float()\n",
    "y_val_tensor = torch.from_numpy(y_val_np).float()\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64c452b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranWallNet(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=64, nhead=8, num_layers=2, dim_feedforward=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Linear(d_model, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer(x)\n",
    "        x = x[:, 0, :]\n",
    "        logits = self.cls_head(x)\n",
    "        return logits.squeeze(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68c3a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_tensor.shape[1]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n",
    "model = TranWallNet(input_dim=input_dim).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd064165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=0.1839 val_loss=0.1808 acc=0.9126 f1=0.9168\n",
      "Epoch 2: train_loss=0.1843 val_loss=0.1752 acc=0.9136 f1=0.9190\n",
      "Epoch 3: train_loss=0.1808 val_loss=0.1788 acc=0.9122 f1=0.9163\n",
      "Epoch 4: train_loss=0.1802 val_loss=0.1825 acc=0.9076 f1=0.9120\n",
      "Epoch 5: train_loss=0.1808 val_loss=0.1822 acc=0.9093 f1=0.9128\n",
      "Epoch 6: train_loss=0.1805 val_loss=0.1752 acc=0.9127 f1=0.9178\n",
      "Epoch 7: train_loss=0.1792 val_loss=0.1723 acc=0.9172 f1=0.9217\n",
      "Epoch 8: train_loss=0.1775 val_loss=0.1836 acc=0.9083 f1=0.9140\n",
      "Epoch 9: train_loss=0.1805 val_loss=0.1775 acc=0.9125 f1=0.9168\n",
      "Epoch 10: train_loss=0.1781 val_loss=0.1731 acc=0.9144 f1=0.9182\n",
      "Epoch 11: train_loss=0.1767 val_loss=0.1728 acc=0.9142 f1=0.9178\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 25\n",
    "best_f1 = 0\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            val_losses.append(loss.item())\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_labels.append(yb.cpu())\n",
    "\n",
    "    all_logits = torch.cat(all_logits)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    probs = torch.sigmoid(all_logits)\n",
    "    preds = (probs >= 0.5).long()\n",
    "\n",
    "    acc = accuracy_score(all_labels.numpy(), preds.numpy())\n",
    "    f1 = f1_score(all_labels.numpy(), preds.numpy())\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        patience_counter = 0  # reset counter when improvement occurs\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter == patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(f\"Epoch {epoch}: train_loss={np.mean(train_losses):.4f} val_loss={np.mean(val_losses):.4f} acc={acc:.4f} f1={f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e2e7a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9167425760612133, 0.9204248650531082)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        logits = model(xb)\n",
    "        all_logits.append(logits.cpu())\n",
    "        all_labels.append(yb.cpu())\n",
    "\n",
    "all_logits = torch.cat(all_logits)\n",
    "all_labels = torch.cat(all_labels)\n",
    "probs = torch.sigmoid(all_logits)\n",
    "preds = (probs >= 0.5).long()\n",
    "\n",
    "val_acc = accuracy_score(all_labels.numpy(), preds.numpy())\n",
    "val_f1 = f1_score(all_labels.numpy(), preds.numpy())\n",
    "\n",
    "val_acc, val_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecc27e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 0.1732 acc: 0.9165  val_f1: 0.9205\n",
      "Epoch 2 - loss: 0.1719 acc: 0.9099  val_f1: 0.9162\n",
      "Epoch 3 - loss: 0.1719 acc: 0.9166  val_f1: 0.9231\n",
      "Epoch 4 - loss: 0.1706 acc: 0.9168  val_f1: 0.9228\n",
      "Epoch 5 - loss: 0.1695 acc: 0.9158  val_f1: 0.9199\n",
      "Epoch 6 - loss: 0.1696 acc: 0.9172  val_f1: 0.9211\n",
      "Epoch 7 - loss: 0.1693 acc: 0.9181  val_f1: 0.9220\n",
      "Epoch 8 - loss: 0.1673 acc: 0.9214  val_f1: 0.9257\n",
      "Epoch 9 - loss: 0.1683 acc: 0.9187  val_f1: 0.9227\n",
      "Epoch 10 - loss: 0.1678 acc: 0.9192  val_f1: 0.9236\n",
      "Epoch 11 - loss: 0.1673 acc: 0.9180  val_f1: 0.9230\n",
      "Epoch 12 - loss: 0.1663 acc: 0.9186  val_f1: 0.9239\n",
      "Epoch 13 - loss: 0.1670 acc: 0.9143  val_f1: 0.9196\n",
      "Early stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", factor=0.5, patience=2\n",
    ")\n",
    "\n",
    "best_f1 = -float(\"inf\")\n",
    "best_state = None\n",
    "patience = 5\n",
    "pat = 0\n",
    "\n",
    "for epoch in range(1, 30):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * xb.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            logits = model(xb)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            all_probs.append(probs)\n",
    "            all_targets.append(yb.cpu().numpy())\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    preds = (all_probs >= 0.5).astype(int)\n",
    "    acc = accuracy_score(all_targets, preds)\n",
    "    val_f1 = f1_score(all_targets, preds)\n",
    "\n",
    "    print(f\"Epoch {epoch} - loss: {epoch_loss:.4f} acc: {acc:.4f}  val_f1: {val_f1:.4f}\")\n",
    "\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_state = model.state_dict()\n",
    "        pat = 0\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "if best_state is None:\n",
    "    best_state = model.state_dict()\n",
    "\n",
    "model.load_state_dict(best_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9446cce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model/tranwall.pt'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = \"model/tranwall.pt\"\n",
    "\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "checkpoint = {\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"input_dim\": input_dim,\n",
    "    \"scaler_mean\": scaler.mean_,\n",
    "    \"scaler_scale\": scaler.scale_\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, save_path)\n",
    "\n",
    "save_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a6855",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tranwall)",
   "language": "python",
   "name": "tranwall"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
